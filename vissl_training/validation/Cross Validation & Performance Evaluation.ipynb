{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3265130",
   "metadata": {},
   "source": [
    "# Cross Validation & Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99d1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt  \n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6571b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdffe4",
   "metadata": {},
   "source": [
    "## Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c71b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blacklist.txt\t\t    moco32_phase75   simclr_phase25\r\n",
      "class_occurences.json\t    moco64\t     simclr_phase50\r\n",
      "gallery_paths_relative.txt  moco64_phase0    simclr_phase75\r\n",
      "gallery_paths.txt\t    moco64_phase25   strict_train_test.json\r\n",
      "imgnet_pretrained\t    moco64_phase50   swav\r\n",
      "jigsaw\t\t\t    moco64_phase75   swav_phase0\r\n",
      "jigsaw_phase0\t\t    random\t     swav_phase25\r\n",
      "jigsaw_phase100\t\t    rotnet\t     swav_phase50\r\n",
      "jigsaw_phase25\t\t    rotnet_phase0    swav_phase75\r\n",
      "jigsaw_phase50\t\t    rotnet_phase100  total_cross_val_log_mlp.txt\r\n",
      "jigsaw_phase75\t\t    rotnet_phase25   total_cross_val_log_svm.txt\r\n",
      "moco32\t\t\t    rotnet_phase50   total_gallery_mAP_scores_log.txt\r\n",
      "moco32_phase0\t\t    rotnet_phase75   total_perf_eval_log_mlp.txt\r\n",
      "moco32_phase25\t\t    simclr\t     total_perf_eval_log_svm.txt\r\n",
      "moco32_phase50\t\t    simclr_phase0\r\n"
     ]
    }
   ],
   "source": [
    "#Models that are available for testing:\n",
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a84d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for model random succesfully read.\n",
      "embedding_gallery size: torch.Size([1643, 2048])\n",
      "embedding_gallery_norm size: torch.Size([1643, 2048])\n",
      "labels length: 1643\n"
     ]
    }
   ],
   "source": [
    "#options rotnet, jigsaw, simclr, moco32, imgnet_pretrained\n",
    "model_name = \"random\" #<----------Specifiy model here!\n",
    "\n",
    "dir = Path(\"data/\" + model_name)\n",
    "\n",
    "embedding_gallery = torch.load(dir / \"embedding_gallery.torch\")\n",
    "embedding_gallery_norm = torch.load(dir / \"embedding_gallery_norm.torch\")\n",
    "labels = list()\n",
    "with open(dir / \"embedding_gallery_labels.txt\", \"r\") as f:\n",
    "    labels = f.read().splitlines()\n",
    "print(f\"Data for model {model_name} succesfully read.\\nembedding_gallery size: {embedding_gallery.shape}\\\n",
    "\\nembedding_gallery_norm size: {embedding_gallery_norm.shape}\\nlabels length: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34586afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_gallery size: (1643, 2048) and type <class 'numpy.ndarray'>\n",
      "embedding_gallery_norm size: (1643, 2048) and type <class 'numpy.ndarray'>\n",
      "Labels with size (1643,) and type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Convert to numpy arrays:\n",
    "embedding_gallery = embedding_gallery.numpy()\n",
    "embedding_gallery_norm = embedding_gallery_norm.numpy()\n",
    "labels = np.array(labels)\n",
    "print(f\"embedding_gallery size: {embedding_gallery.shape} and type {type(embedding_gallery)}\\\n",
    "\\nembedding_gallery_norm size: {embedding_gallery_norm.shape} and type {type(embedding_gallery_norm)}\\\n",
    "\\nLabels with size {labels.shape} and type {type(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31c8c0",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e183256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc94144",
   "metadata": {},
   "source": [
    "Let's test the performance of a support vector machine (SVM) and a multi layer perceptron (MLP) on the entire data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SVM estimator \n",
    "svm_overfit = SVC(kernel=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec450eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create MLP estimator\n",
    "mlp_overfit = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 64),\n",
    "    solver='lbfgs',\n",
    "    max_iter=10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753bf709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dat to train/fit on \n",
    "data = embedding_gallery_norm.copy()\n",
    "#labels are already in a numpy array called \"labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd682f",
   "metadata": {},
   "source": [
    "Training/fitting on the data and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train SVM\n",
    "svm_overfit.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d02059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train MLP\n",
    "mlp_overfit.fit(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be5903",
   "metadata": {},
   "source": [
    "Evaluate on the same data (this is overfitting, but should yield high results and verify that the data is correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate SVM\n",
    "accuracy = svm_overfit.score(data, labels) \n",
    "print(f\"Accuracy svm: {accuracy*100:.1f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate MLP\n",
    "accuracy = mlp_overfit.score(data, labels) \n",
    "print(f\"Accuracy mlp: {accuracy*100:.1f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56fb2dc",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "077b0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d6a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(classifier, fold, data, labels):\n",
    "    \"\"\"\n",
    "    Performs a cross validation for the classifier with a train test split\n",
    "    according to fold generator.\n",
    "    \n",
    "    Args:\n",
    "        classifier: the classifier to cross validate.\n",
    "        fold: the generator to use for train-test splits.\n",
    "        data: the embedding gallery to train/test on.\n",
    "        labels: the ground truth labels per row for the gallery.\n",
    "        \n",
    "    Returns:\n",
    "        The mean accuracy score from the cross validation rounds and\n",
    "        the standard deviation of the scores.\n",
    "    \"\"\"\n",
    "    #cross validation generator\n",
    "    cv = fold.split(data, y=labels)\n",
    "\n",
    "    #calc cross validation\n",
    "    scores = cross_val_score(\n",
    "        classifier,   #the estimator/classifier\n",
    "        data,         #data \n",
    "        y=labels,     #targets\n",
    "        cv=cv         #generator for array indicis in data that select a certain split out of \"data\"\n",
    "    )\n",
    "    print(scores)\n",
    "    accuracy = scores.mean()\n",
    "    std = scores.std()\n",
    "    return accuracy, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21caf16",
   "metadata": {},
   "source": [
    "Now let's create an svm and mlp that we don't overfit. We will test it's ability to generalize by performing cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SVM estimator \n",
    "svm_cross = SVC(kernel=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create MLP estimator\n",
    "mlp_cross = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    solver='lbfgs',\n",
    "    max_iter=10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61993edb",
   "metadata": {},
   "source": [
    "Create cross validation generators for train-test splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f039e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterators = { \n",
    "    \"KFold\" : KFold(n_splits=5), \n",
    "    \"StratifiedKFold\" : StratifiedKFold(n_splits=5), \n",
    "    \"ShuffleSplit\" : ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "}\n",
    "\n",
    "for k in iterators.keys():\n",
    "    print(f\"Generator/iterator used: {k}\")\n",
    "    iterator = iterators[k]\n",
    "    for i, (train_index, test_index) in enumerate(iterator.split(data, y=labels)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index[:5] {train_index[:5]} with shape{train_index.shape}\")\n",
    "        print(f\"  Test:  index[:5] {test_index[:5]} with shape{test_index.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create KFold generator\n",
    "#5 folds with 1/5 test data and 4/5 training data to cross validate\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91d5ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create StratifiedKFold generator\n",
    "#5 folds with 1/5 test data and 4/5 training data to cross validate. \n",
    "#The folds have equal class distribution in this case\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e57e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ShuffleSplit generator\n",
    "#samples are shuffled and then split up in a test and train set\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38333d77",
   "metadata": {},
   "source": [
    "Perform the cross validations on svm and mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5822376",
   "metadata": {},
   "source": [
    "### SVM cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56756c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with KFold\n",
    "accuracy, std = cross_validate(svm_cross, kf, data, labels)\n",
    "print(f\"Support Vector Machine (SVM) with KFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de979f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with StratifiedKFold\n",
    "accuracy, std = cross_validate(svm_cross, skf, data, labels)\n",
    "print(f\"Support Vector Machine (SVM) with StratifiedKFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ShuffleSplit\n",
    "accuracy, std = cross_validate(svm_cross, ss, data, labels)\n",
    "print(f\"Support Vector Machine (SVM) with ShuffleSplit:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b825ce",
   "metadata": {},
   "source": [
    "### MLP cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0570c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with KFold\n",
    "accuracy, std = cross_validate(mlp_cross, kf, data, labels)\n",
    "print(f\"Multi Layer Perceptron (MLP) with KFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with StratifiedKFold\n",
    "accuracy, std = cross_validate(mlp_cross, skf, data, labels)\n",
    "print(f\"Multi Layer Perceptron (MLP) with StratifiedKFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ShuffleSplit\n",
    "accuracy, std = cross_validate(mlp_cross, ss, data, labels)\n",
    "print(f\"Multi Layer Perceptron (MLP) with ShuffleSplit:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddfbc0",
   "metadata": {},
   "source": [
    "## Performance Assessment \n",
    "In this section we will do the final test.\n",
    "- Split up the data from cornershop in train (80%) and test (20%) data.\n",
    "- Cross validate on the training set.\n",
    "- Fit on the training set.\n",
    "- Test on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab9b2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64fdbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_performance(classifier, train_set, train_labels, test_set, test_labels):\n",
    "    \"\"\"\n",
    "    Evaluate performance for the given estimator/classifier.\n",
    "    Performance is measured by:\n",
    "        -Training on the train_set and train_labels\n",
    "        -Measuring accuracy for classification on the test_set with the test_labels\n",
    "        -Calculate a confusion matrix\n",
    "    \n",
    "    Args:\n",
    "        classifier : the classifier to evaluate.\n",
    "        train_set (np.ndarray): the data to train on.\n",
    "        train_labels (np.ndarray): ground truth for training data.\n",
    "        test_set (np.ndarray): the data to test on.\n",
    "        test_labels (np.ndarray): ground truth for testing data.\n",
    "        \n",
    "    Returns:\n",
    "        accuracy : accuracy score from predictions on test set.\n",
    "        cm: The confusion matrix.\n",
    "    \"\"\"\n",
    "    #train on training set\n",
    "    classifier.fit(train_set, train_labels) #retrain on training set\n",
    "    \n",
    "    #Calculate accuracy\n",
    "    accuracy = classifier.score(test_set, test_labels) #calc acc score on testing set\n",
    "    \n",
    "    #Calculate confusion matrix\n",
    "    y_true = test_labels.copy() #Ground truth\n",
    "    y_pred = classifier.predict(test_set) #Predictions made by classifier\n",
    "    proba = classifier.predict_proba(test_set)\n",
    "    cls = classifier.classes_\n",
    "    print(f\"shape proba is {proba.shape}\\n examples {proba[:4]}\")\n",
    "    print(f\"sgapr classes {cls.shape}, examples {cls[:4]}\")\n",
    "    print(f\"shape test is {test_set.shape}\\n examples {test_set[:4]}\")\n",
    "    print(f\"amount of classes in test set {len(np.unique(test_labels))}\\n\")\n",
    "    print(f\"shape y_pred is {y_pred.shape}\\n examples {y_pred[:4]}\")\n",
    "    #compute confusion matrix\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    #predicted class is the column nr, ground truth is the row nr\n",
    "    #correct classifications can be found on the diagonal\n",
    "\n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734298c7",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1440ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, train_labels, test_labels= train_test_split(\n",
    "    data,          #data\n",
    "    labels,        #targets\n",
    "    test_size=0.2, #20% test set, 80% train set\n",
    "    random_state=0 #for reproducable results of the random shuffling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbdc85da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "[[0.04078872 0.03530824 0.00678304 ... 0.03306351 0.01726185 0.03610783]\n",
      " [0.04064573 0.0363175  0.00599212 ... 0.03440046 0.01788658 0.03525334]\n",
      " [0.0424205  0.03523001 0.00580871 ... 0.0335947  0.01733422 0.03480563]\n",
      " [0.04106166 0.0362539  0.00684298 ... 0.03334849 0.01874477 0.03872367]\n",
      " [0.04268859 0.03532639 0.00594792 ... 0.0351269  0.01742237 0.03658667]] \n",
      "\n",
      "train_labels \n",
      "['MayTeaFramboos1L' 'MonsterPipelinePunch500ml' 'AquariusOrangeFles'\n",
      " 'MonsterUltra' 'PepsiMax']\n"
     ]
    }
   ],
   "source": [
    "#our training set looks like this\n",
    "print(f\"train set\\n{train_set[:5]} \\n\\ntrain_labels \\n{train_labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fabcc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set\n",
      "[[0.04198815 0.03486998 0.00615037 ... 0.03400399 0.01776142 0.036527  ]\n",
      " [0.04279465 0.03503878 0.00742215 ... 0.03626968 0.0162737  0.03606767]\n",
      " [0.04264008 0.03634319 0.00699273 ... 0.03464346 0.01640888 0.03668126]\n",
      " [0.04302761 0.03545025 0.00602863 ... 0.03395331 0.01711669 0.03462484]\n",
      " [0.04186171 0.03634463 0.00635983 ... 0.03284569 0.01839124 0.03855904]] \n",
      "\n",
      "test_labels \n",
      "['InnocentOrangeWithBits' 'CapriSun' 'MonsterPunchEnergy500ml'\n",
      " 'NaluOriginal6x350ml' 'StellaBlik50cl']\n"
     ]
    }
   ],
   "source": [
    "#our test set looks like this\n",
    "print(f\"test set\\n{test_set[:5]} \\n\\ntest_labels \\n{test_labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a0cc700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set 1314\n",
      "The training set contains 79.97565429093122% of the data\n",
      "\n",
      "Size of the test set 329\n",
      "The test set contains 20.02434570906878% of the data\n"
     ]
    }
   ],
   "source": [
    "#Proportion of training data\n",
    "prop_train = (len(train_set)/ len(embedding_gallery_norm) ) * 100\n",
    "#Proportion of testing data\n",
    "prop_test = (len(test_set)/ len(embedding_gallery_norm) ) * 100\n",
    "print(f\"Size of the training set {len(train_set)}\\nThe training set contains {prop_train}% of the data\\n\")\n",
    "print(f\"Size of the test set {len(test_set)}\\nThe test set contains {prop_test}% of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39785d",
   "metadata": {},
   "source": [
    "### Cross validation on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78382816",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SVM estimator \n",
    "svm_test = SVC(kernel=\"poly\", probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ee4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create StratifiedKFold generator\n",
    "#5 folds with 1/5 test data and 4/5 training data to cross validate. \n",
    "#The folds have equal class distribution in this case\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the cross validation\n",
    "accuracy, std = cross_validate(svm_test, skf, train_set, train_labels)\n",
    "print(f\"Support Vector Machine (SVM) with StratifiedKFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8165f7",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5081b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create MLP estimator\n",
    "mlp_test = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    solver='lbfgs',\n",
    "    max_iter=10_000,\n",
    "    alpha=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88848b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create StratifiedKFold generator\n",
    "#5 folds with 1/5 test data and 4/5 training data to cross validate. \n",
    "#The folds have equal class distribution in this case\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65d9984b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3460076  0.30798479 0.27756654 0.23574144 0.32824427]\n",
      "Multi Layer Perceptron (MLP) with StratifiedKFold:\n",
      "Accuracy: 29.9% \n",
      "std_dev: 0.039004224492825805\n",
      "\n",
      "57min 58s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 #time cell excecution by running it only once\n",
    "#Perform the cross validation\n",
    "accuracy, std = cross_validate(mlp_test, skf, train_set, train_labels)\n",
    "print(f\"Multi Layer Perceptron (MLP) with StratifiedKFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21f1c1",
   "metadata": {},
   "source": [
    "### Testing on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32386a85",
   "metadata": {},
   "source": [
    "#### Suport Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3283e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy, cm = eval_performance(svm_test, train_set, train_labels, test_set, test_labels)\n",
    "print(f\"Support Vector Machine (SVM):\\nAccuracy: {accuracy*100:.1f}% \\nconfusion_matrix: \\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b15537",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00b011d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape proba is (329, 384)\n",
      " examples [[4.65709577e-12 1.07960457e-05 7.78955650e-13 ... 1.22585036e-14\n",
      "  5.77362896e-18 9.84162609e-07]\n",
      " [2.15507052e-25 3.57265629e-21 1.77578006e-16 ... 4.40905041e-22\n",
      "  6.53800761e-20 1.10062926e-29]\n",
      " [8.16649973e-10 5.83621811e-11 2.79276050e-06 ... 1.29708713e-13\n",
      "  2.53487470e-11 1.14303914e-13]\n",
      " [9.99729143e-04 1.99477710e-09 1.51196594e-02 ... 9.07805973e-28\n",
      "  3.61220578e-27 2.74375173e-09]]\n",
      "sgapr classes (384,), examples ['7upFree' '7upLemon' '7upMojito' 'AADrink']\n",
      "shape test is (329, 2048)\n",
      " examples [[0.04198815 0.03486998 0.00615037 ... 0.03400399 0.01776142 0.036527  ]\n",
      " [0.04279465 0.03503878 0.00742215 ... 0.03626968 0.0162737  0.03606767]\n",
      " [0.04264008 0.03634319 0.00699273 ... 0.03464346 0.01640888 0.03668126]\n",
      " [0.04302761 0.03545025 0.00602863 ... 0.03395331 0.01711669 0.03462484]]\n",
      "amount of classes in test set 194\n",
      "\n",
      "shape y_pred is (329,)\n",
      " examples ['InnocentOrangeWithBits' 'CapriSun' 'ChaudfontaineSensation'\n",
      " 'NaluOriginal6x350ml']\n",
      "Multi Layer Perceptron:\n",
      "Accuracy: 30.4% \n",
      "confusion_matrix: \n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "12min 10s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/Documents/master/mp/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 #time cell excecution by running it only once\n",
    "accuracy, cm = eval_performance(mlp_test, train_set, train_labels, test_set, test_labels)\n",
    "print(f\"Multi Layer Perceptron:\\nAccuracy: {accuracy*100:.1f}% \\nconfusion_matrix: \\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7379133",
   "metadata": {},
   "source": [
    "## Strict Peformance Assessment \n",
    "In this section we will do the final test with a sticter test set.\n",
    "This means that every embedding in the test set is from a different origin image than every embedding from the same class in the train set.\n",
    "- Collect the split from a json file which aims to achieve a 80/20 train/test split.\n",
    "- Cross validate on the strict training set.\n",
    "- Fit on the strict training set.\n",
    "- Test on the strict testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243d3a1",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = Path(\"data/strict_train_test.json\")\n",
    "# Read the JSON file\n",
    "with open(json_file, \"r\") as file:\n",
    "    json_data = file.read()\n",
    "\n",
    "# Convert JSON to dictionary\n",
    "strict_train_test = json.loads(json_data)\n",
    "\n",
    "# Access the dictionary\n",
    "print(f\"Amount of classes that can be used for strict testing: {len(strict_train_test.keys())} / {len(np.unique(labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b26cb",
   "metadata": {},
   "source": [
    "Lets set up the strict test and train set <br>\n",
    "We have a copy of embedding gallery norm in `data` and the corresponding labels are in the variable `labels`. <br>\n",
    "We have the indicis of embeddings in the gallery already determined in the json file, let's apply them to get our train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_strict = []\n",
    "train_labels_strict = [] \n",
    "test_set_strict = []\n",
    "test_labels_strict = []\n",
    "for cls in strict_train_test.keys():\n",
    "    #Collect train queries\n",
    "    train_queries = strict_train_test[cls][\"train\"]\n",
    "    for query in train_queries:\n",
    "        idx = query[\"gallery_idx\"]\n",
    "        train_query = data[idx]\n",
    "        train_label = labels[idx]\n",
    "        train_set_strict.append(train_query)\n",
    "        train_labels_strict.append(train_label)\n",
    "    \n",
    "    #Collect test queries\n",
    "    test_queries = strict_train_test[cls][\"test\"]\n",
    "    for query in test_queries:\n",
    "        idx = query[\"gallery_idx\"]\n",
    "        test_query = data[idx]\n",
    "        test_label = labels[idx]\n",
    "        test_set_strict.append(test_query)\n",
    "        test_labels_strict.append(test_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_strict = np.array(train_set_strict)\n",
    "test_set_strict = np.array(test_set_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9027be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our training set looks like this\n",
    "print(f\"train set\\n{train_set_strict[:5]} \\n\\ntrain_labels \\n{train_labels_strict[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our test set looks like this\n",
    "print(f\"test set\\n{test_set_strict[:5]} \\n\\ntest_labels \\n{test_labels_strict[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion of training data\n",
    "prop_train = (len(train_set_strict)/ (len(train_set_strict) + len(test_set_strict)) ) * 100\n",
    "#Proportion of testing data\n",
    "prop_test = (len(test_set_strict)/ (len(train_set_strict) + len(test_set_strict)) ) * 100\n",
    "print(f\"Size of the training set {len(train_set_strict)}\\nThe training set contains {prop_train}% of the data\\n\")\n",
    "print(f\"Size of the test set {len(test_set_strict)}\\nThe test set contains {prop_test}% of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785c1ee",
   "metadata": {},
   "source": [
    "### Cross validation on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e7c58",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dda15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SVM estimator \n",
    "svm_test_strict = SVC(kernel=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create StratifiedKFold generator\n",
    "#5 folds with 1/5 test data and 4/5 training data to cross validate. \n",
    "#The folds have equal class distribution in this case\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the cross validation\n",
    "accuracy, std = cross_validate(svm_test_strict, skf, train_set_strict, train_labels_strict)\n",
    "print(f\"Support Vector Machine (SVM) with StratifiedKFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730227f",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create MLP estimator\n",
    "mlp_test_strict = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 64),\n",
    "    solver='lbfgs',\n",
    "    max_iter=10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create StratifiedKFold generator\n",
    "#5 folds with 1/5 test data and 4/5 training data to cross validate. \n",
    "#The folds have equal class distribution in this case\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85097167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the cross validation\n",
    "accuracy, std = cross_validate(mlp_test_strict, skf, train_set_strict, train_labels_strict)\n",
    "print(f\"Multi Layer Perceptron (MLP) with StratifiedKFold:\\nAccuracy: {accuracy*100:.1f}% \\nstd_dev: {std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4047c27",
   "metadata": {},
   "source": [
    "### Testing on the strict test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6d407",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, cm = eval_performance(\n",
    "    svm_test_strict, \n",
    "    train_set_strict, \n",
    "    train_labels_strict, \n",
    "    test_set_strict, \n",
    "    test_labels_strict\n",
    ")\n",
    "print(f\"Support Vector Machine (SVM):\\nAccuracy: {accuracy*100:.1f}% \\nconfusion_matrix: \\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc98cd",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96231f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, cm = eval_performance(\n",
    "    mlp_test_strict, \n",
    "    train_set_strict, \n",
    "    train_labels_strict, \n",
    "    test_set_strict, \n",
    "    test_labels_strict\n",
    ")\n",
    "print(f\"Multi Layer Perceptron:\\nAccuracy: {accuracy*100:.1f}% \\nconfusion_matrix: \\n{cm}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
